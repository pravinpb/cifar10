{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.regularizers import l2 as l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/bf3hb7111_5fnn18n3p6z4rm0000gn/T/ipykernel_88588/3775580566.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperModel\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from kerastuner import HyperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Normal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.8301 - loss: 0.4843 - val_accuracy: 0.6984 - val_loss: 1.0186\n",
      "Epoch 2/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8393 - loss: 0.4498 - val_accuracy: 0.7043 - val_loss: 1.0351\n",
      "Epoch 3/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8603 - loss: 0.4039 - val_accuracy: 0.6937 - val_loss: 1.0710\n",
      "Epoch 4/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8704 - loss: 0.3658 - val_accuracy: 0.6950 - val_loss: 1.1066\n",
      "Epoch 5/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8797 - loss: 0.3335 - val_accuracy: 0.6859 - val_loss: 1.1756\n",
      "Epoch 6/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.8930 - loss: 0.2998 - val_accuracy: 0.6945 - val_loss: 1.2446\n",
      "Epoch 7/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9028 - loss: 0.2769 - val_accuracy: 0.6932 - val_loss: 1.3037\n",
      "Epoch 8/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9099 - loss: 0.2515 - val_accuracy: 0.6906 - val_loss: 1.3632\n",
      "Epoch 9/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9156 - loss: 0.2360 - val_accuracy: 0.6800 - val_loss: 1.4931\n",
      "Epoch 10/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9227 - loss: 0.2163 - val_accuracy: 0.6817 - val_loss: 1.4912\n",
      "Epoch 11/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9314 - loss: 0.1960 - val_accuracy: 0.6894 - val_loss: 1.6014\n",
      "Epoch 12/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9330 - loss: 0.1878 - val_accuracy: 0.6818 - val_loss: 1.6011\n",
      "Epoch 13/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9379 - loss: 0.1757 - val_accuracy: 0.6740 - val_loss: 1.8067\n",
      "Epoch 14/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9418 - loss: 0.1631 - val_accuracy: 0.6827 - val_loss: 1.8080\n",
      "Epoch 15/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9417 - loss: 0.1636 - val_accuracy: 0.6758 - val_loss: 1.9257\n",
      "Epoch 16/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9469 - loss: 0.1490 - val_accuracy: 0.6841 - val_loss: 1.9488\n",
      "Epoch 17/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9493 - loss: 0.1468 - val_accuracy: 0.6737 - val_loss: 1.9990\n",
      "Epoch 18/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9512 - loss: 0.1368 - val_accuracy: 0.6701 - val_loss: 2.1135\n",
      "Epoch 19/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9529 - loss: 0.1347 - val_accuracy: 0.6757 - val_loss: 2.1088\n",
      "Epoch 20/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9496 - loss: 0.1402 - val_accuracy: 0.6640 - val_loss: 2.2729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x148085610>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=20, batch_size=20, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6651 - loss: 2.1798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2744457721710205, 0.6617000102996826]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test / 255.0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('cifar10_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Keras Tuner*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First convolutional layer\n",
    "    hp_filters_1 = hp.Int('filters_1', min_value=32, max_value=128, step=32)  # Tune filters\n",
    "    hp_kernel_1 = hp.Choice('kernel_size_1', values=[3, 5])  # Tune kernel size\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])  # Tune activation function\n",
    "\n",
    "    model.add(Conv2D(filters=hp_filters_1, \n",
    "                     kernel_size=(hp_kernel_1, hp_kernel_1), \n",
    "                     activation=hp_activation, \n",
    "                     input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  # Static pooling layer\n",
    "\n",
    "    # Second convolutional layer\n",
    "    hp_filters_2 = hp.Int('filters_2', min_value=64, max_value=256, step=64)\n",
    "    hp_kernel_2 = hp.Choice('kernel_size_2', values=[3, 5])\n",
    "\n",
    "    model.add(Conv2D(filters=hp_filters_2, \n",
    "                     kernel_size=(hp_kernel_2, hp_kernel_2), \n",
    "                     activation=hp_activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Third convolutional layer\n",
    "    hp_filters_3 = hp.Int('filters_3', min_value=64, max_value=256, step=64)\n",
    "    model.add(Conv2D(filters=hp_filters_3, \n",
    "                     kernel_size=(3, 3), \n",
    "                     activation=hp_activation))\n",
    "\n",
    "    # Flatten the feature maps\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dense layer with tunable units\n",
    "    hp_dense_units = hp.Int('dense_units', min_value=64, max_value=512, step=64)\n",
    "    model.add(Dense(units=hp_dense_units, activation=hp_activation))\n",
    "\n",
    "    # Output layer for 10 classes\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',  # We want to optimize for validation accuracy\n",
    "    max_epochs=10,  # Number of epochs to run for each trial\n",
    "    factor=3,  # Controls the resource allocation between trials\n",
    "    directory='hyperband_results',  # Directory to store results\n",
    "    project_name='cifar10_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 02m 47s]\n",
      "val_accuracy: 0.6406999826431274\n",
      "\n",
      "Best val_accuracy So Far: 0.7251999974250793\n",
      "Total elapsed time: 01h 18m 54s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, Y_train, epochs=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 41ms/step - accuracy: 0.8338 - loss: 0.4674 - val_accuracy: 0.7238 - val_loss: 0.9001\n",
      "Epoch 2/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 44ms/step - accuracy: 0.8709 - loss: 0.3657 - val_accuracy: 0.7265 - val_loss: 0.9164\n",
      "Epoch 3/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - accuracy: 0.8851 - loss: 0.3227 - val_accuracy: 0.7311 - val_loss: 0.9682\n",
      "Epoch 4/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 44ms/step - accuracy: 0.9049 - loss: 0.2677 - val_accuracy: 0.7189 - val_loss: 1.1136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x387166750>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, Y_train, epochs=50, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7203 - loss: 1.1297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.135772705078125, 0.7166000008583069]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(x_test / 255.0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "best_model.save('cifar10_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_2(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer with data augmentation\n",
    "    model.add(tf.keras.layers.RandomFlip(\"horizontal\"))\n",
    "    model.add(tf.keras.layers.RandomRotation(0.2))\n",
    "\n",
    "    # First convolutional block\n",
    "    hp_filters_1 = hp.Int('filters_1', min_value=32, max_value=128, step=32)\n",
    "    hp_kernel_1 = hp.Choice('kernel_size_1', values=[3, 5])\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh', 'elu'])\n",
    "\n",
    "    model.add(Conv2D(filters=hp_filters_1, \n",
    "                     kernel_size=(hp_kernel_1, hp_kernel_1), \n",
    "                     activation=hp_activation, \n",
    "                     kernel_regularizer=l2(1e-4), \n",
    "                     input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Second convolutional block\n",
    "    hp_filters_2 = hp.Int('filters_2', min_value=64, max_value=256, step=64)\n",
    "    hp_kernel_2 = hp.Choice('kernel_size_2', values=[3, 5])\n",
    "\n",
    "    model.add(Conv2D(filters=hp_filters_2, \n",
    "                     kernel_size=(hp_kernel_2, hp_kernel_2), \n",
    "                     activation=hp_activation, \n",
    "                     kernel_regularizer=l2(1e-4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Flatten and Dense layers\n",
    "    model.add(Flatten())\n",
    "    hp_dense_units = hp.Int('dense_units', min_value=64, max_value=512, step=64)\n",
    "    model.add(Dense(units=hp_dense_units, activation=hp_activation, kernel_regularizer=l2(1e-4)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate_dense', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder_2,\n",
    "    objective='val_accuracy',  # We want to optimize for validation accuracy\n",
    "    max_epochs=10,  # Number of epochs to run for each trial\n",
    "    factor=3,  # Controls the resource allocation between trials\n",
    "    directory='hyperband_results_2',  # Directory to store results\n",
    "    project_name='cifar10_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 11m 06s]\n",
      "val_accuracy: 0.45980000495910645\n",
      "\n",
      "Best val_accuracy So Far: 0.6133999824523926\n",
      "Total elapsed time: 03h 08m 07s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, Y_train, epochs=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_model_3 = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 148ms/step - accuracy: 0.5623 - loss: 1.5247 - val_accuracy: 0.5757 - val_loss: 1.5009\n",
      "Epoch 2/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 142ms/step - accuracy: 0.5730 - loss: 1.4927 - val_accuracy: 0.5987 - val_loss: 1.4333\n",
      "Epoch 3/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 139ms/step - accuracy: 0.5829 - loss: 1.4728 - val_accuracy: 0.5361 - val_loss: 1.7105\n",
      "Epoch 4/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 140ms/step - accuracy: 0.5924 - loss: 1.4524 - val_accuracy: 0.6369 - val_loss: 1.3695\n",
      "Epoch 5/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 137ms/step - accuracy: 0.5987 - loss: 1.4598 - val_accuracy: 0.6411 - val_loss: 1.3650\n",
      "Epoch 6/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 139ms/step - accuracy: 0.6007 - loss: 1.4476 - val_accuracy: 0.6357 - val_loss: 1.3400\n",
      "Epoch 7/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 138ms/step - accuracy: 0.6103 - loss: 1.4286 - val_accuracy: 0.6167 - val_loss: 1.4299\n",
      "Epoch 8/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 136ms/step - accuracy: 0.6176 - loss: 1.4090 - val_accuracy: 0.5865 - val_loss: 1.5196\n",
      "Epoch 9/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 139ms/step - accuracy: 0.6212 - loss: 1.3974 - val_accuracy: 0.6300 - val_loss: 1.3760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3d80ecb10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_3.fit(X_train, Y_train, epochs=50, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.6252 - loss: 1.3848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.385072112083435, 0.6263999938964844]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_3.evaluate(x_test / 255.0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
