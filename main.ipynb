{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.regularizers import l2 as l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/bf3hb7111_5fnn18n3p6z4rm0000gn/T/ipykernel_88588/3775580566.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperModel\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from kerastuner import HyperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Normal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.8301 - loss: 0.4843 - val_accuracy: 0.6984 - val_loss: 1.0186\n",
      "Epoch 2/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8393 - loss: 0.4498 - val_accuracy: 0.7043 - val_loss: 1.0351\n",
      "Epoch 3/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8603 - loss: 0.4039 - val_accuracy: 0.6937 - val_loss: 1.0710\n",
      "Epoch 4/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8704 - loss: 0.3658 - val_accuracy: 0.6950 - val_loss: 1.1066\n",
      "Epoch 5/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8797 - loss: 0.3335 - val_accuracy: 0.6859 - val_loss: 1.1756\n",
      "Epoch 6/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.8930 - loss: 0.2998 - val_accuracy: 0.6945 - val_loss: 1.2446\n",
      "Epoch 7/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9028 - loss: 0.2769 - val_accuracy: 0.6932 - val_loss: 1.3037\n",
      "Epoch 8/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9099 - loss: 0.2515 - val_accuracy: 0.6906 - val_loss: 1.3632\n",
      "Epoch 9/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9156 - loss: 0.2360 - val_accuracy: 0.6800 - val_loss: 1.4931\n",
      "Epoch 10/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9227 - loss: 0.2163 - val_accuracy: 0.6817 - val_loss: 1.4912\n",
      "Epoch 11/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9314 - loss: 0.1960 - val_accuracy: 0.6894 - val_loss: 1.6014\n",
      "Epoch 12/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9330 - loss: 0.1878 - val_accuracy: 0.6818 - val_loss: 1.6011\n",
      "Epoch 13/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9379 - loss: 0.1757 - val_accuracy: 0.6740 - val_loss: 1.8067\n",
      "Epoch 14/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9418 - loss: 0.1631 - val_accuracy: 0.6827 - val_loss: 1.8080\n",
      "Epoch 15/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9417 - loss: 0.1636 - val_accuracy: 0.6758 - val_loss: 1.9257\n",
      "Epoch 16/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9469 - loss: 0.1490 - val_accuracy: 0.6841 - val_loss: 1.9488\n",
      "Epoch 17/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9493 - loss: 0.1468 - val_accuracy: 0.6737 - val_loss: 1.9990\n",
      "Epoch 18/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.9512 - loss: 0.1368 - val_accuracy: 0.6701 - val_loss: 2.1135\n",
      "Epoch 19/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9529 - loss: 0.1347 - val_accuracy: 0.6757 - val_loss: 2.1088\n",
      "Epoch 20/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9496 - loss: 0.1402 - val_accuracy: 0.6640 - val_loss: 2.2729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x148085610>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=20, batch_size=20, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6651 - loss: 2.1798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2744457721710205, 0.6617000102996826]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test / 255.0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('cifar10_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Keras Tuner*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First convolutional layer\n",
    "    hp_filters_1 = hp.Int('filters_1', min_value=32, max_value=128, step=32)  # Tune filters\n",
    "    hp_kernel_1 = hp.Choice('kernel_size_1', values=[3, 5])  # Tune kernel size\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])  # Tune activation function\n",
    "\n",
    "    model.add(Conv2D(filters=hp_filters_1, \n",
    "                     kernel_size=(hp_kernel_1, hp_kernel_1), \n",
    "                     activation=hp_activation, \n",
    "                     input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  # Static pooling layer\n",
    "\n",
    "    # Second convolutional layer\n",
    "    hp_filters_2 = hp.Int('filters_2', min_value=64, max_value=256, step=64)\n",
    "    hp_kernel_2 = hp.Choice('kernel_size_2', values=[3, 5])\n",
    "\n",
    "    model.add(Conv2D(filters=hp_filters_2, \n",
    "                     kernel_size=(hp_kernel_2, hp_kernel_2), \n",
    "                     activation=hp_activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Third convolutional layer\n",
    "    hp_filters_3 = hp.Int('filters_3', min_value=64, max_value=256, step=64)\n",
    "    model.add(Conv2D(filters=hp_filters_3, \n",
    "                     kernel_size=(3, 3), \n",
    "                     activation=hp_activation))\n",
    "\n",
    "    # Flatten the feature maps\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dense layer with tunable units\n",
    "    hp_dense_units = hp.Int('dense_units', min_value=64, max_value=512, step=64)\n",
    "    model.add(Dense(units=hp_dense_units, activation=hp_activation))\n",
    "\n",
    "    # Output layer for 10 classes\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',  # We want to optimize for validation accuracy\n",
    "    max_epochs=10,  # Number of epochs to run for each trial\n",
    "    factor=3,  # Controls the resource allocation between trials\n",
    "    directory='hyperband_results',  # Directory to store results\n",
    "    project_name='cifar10_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 02m 47s]\n",
      "val_accuracy: 0.6406999826431274\n",
      "\n",
      "Best val_accuracy So Far: 0.7251999974250793\n",
      "Total elapsed time: 01h 18m 54s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, Y_train, epochs=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 41ms/step - accuracy: 0.8338 - loss: 0.4674 - val_accuracy: 0.7238 - val_loss: 0.9001\n",
      "Epoch 2/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 44ms/step - accuracy: 0.8709 - loss: 0.3657 - val_accuracy: 0.7265 - val_loss: 0.9164\n",
      "Epoch 3/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - accuracy: 0.8851 - loss: 0.3227 - val_accuracy: 0.7311 - val_loss: 0.9682\n",
      "Epoch 4/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 44ms/step - accuracy: 0.9049 - loss: 0.2677 - val_accuracy: 0.7189 - val_loss: 1.1136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x387166750>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, Y_train, epochs=50, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7203 - loss: 1.1297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.135772705078125, 0.7166000008583069]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(x_test / 255.0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "best_model.save('cifar10_model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*With Regularization and Normalization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_2(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer with data augmentation\n",
    "    model.add(tf.keras.layers.RandomFlip(\"horizontal\"))\n",
    "    model.add(tf.keras.layers.RandomRotation(0.2))\n",
    "\n",
    "    # First convolutional block\n",
    "    hp_filters_1 = hp.Int('filters_1', min_value=32, max_value=128, step=32)\n",
    "    hp_kernel_1 = hp.Choice('kernel_size_1', values=[3, 5])\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh', 'elu'])\n",
    "\n",
    "    model.add(Conv2D(filters=hp_filters_1, \n",
    "                     kernel_size=(hp_kernel_1, hp_kernel_1), \n",
    "                     activation=hp_activation, \n",
    "                     kernel_regularizer=l2(1e-4), \n",
    "                     input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Second convolutional block\n",
    "    hp_filters_2 = hp.Int('filters_2', min_value=64, max_value=256, step=64)\n",
    "    hp_kernel_2 = hp.Choice('kernel_size_2', values=[3, 5])\n",
    "\n",
    "    model.add(Conv2D(filters=hp_filters_2, \n",
    "                     kernel_size=(hp_kernel_2, hp_kernel_2), \n",
    "                     activation=hp_activation, \n",
    "                     kernel_regularizer=l2(1e-4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Flatten and Dense layers\n",
    "    model.add(Flatten())\n",
    "    hp_dense_units = hp.Int('dense_units', min_value=64, max_value=512, step=64)\n",
    "    model.add(Dense(units=hp_dense_units, activation=hp_activation, kernel_regularizer=l2(1e-4)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate_dense', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder_2,\n",
    "    objective='val_accuracy',  # We want to optimize for validation accuracy\n",
    "    max_epochs=10,  # Number of epochs to run for each trial\n",
    "    factor=3,  # Controls the resource allocation between trials\n",
    "    directory='hyperband_results_2',  # Directory to store results\n",
    "    project_name='cifar10_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 11m 06s]\n",
      "val_accuracy: 0.45980000495910645\n",
      "\n",
      "Best val_accuracy So Far: 0.6133999824523926\n",
      "Total elapsed time: 03h 08m 07s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, Y_train, epochs=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_model_3 = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 148ms/step - accuracy: 0.5623 - loss: 1.5247 - val_accuracy: 0.5757 - val_loss: 1.5009\n",
      "Epoch 2/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 142ms/step - accuracy: 0.5730 - loss: 1.4927 - val_accuracy: 0.5987 - val_loss: 1.4333\n",
      "Epoch 3/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 139ms/step - accuracy: 0.5829 - loss: 1.4728 - val_accuracy: 0.5361 - val_loss: 1.7105\n",
      "Epoch 4/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 140ms/step - accuracy: 0.5924 - loss: 1.4524 - val_accuracy: 0.6369 - val_loss: 1.3695\n",
      "Epoch 5/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 137ms/step - accuracy: 0.5987 - loss: 1.4598 - val_accuracy: 0.6411 - val_loss: 1.3650\n",
      "Epoch 6/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 139ms/step - accuracy: 0.6007 - loss: 1.4476 - val_accuracy: 0.6357 - val_loss: 1.3400\n",
      "Epoch 7/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 138ms/step - accuracy: 0.6103 - loss: 1.4286 - val_accuracy: 0.6167 - val_loss: 1.4299\n",
      "Epoch 8/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 136ms/step - accuracy: 0.6176 - loss: 1.4090 - val_accuracy: 0.5865 - val_loss: 1.5196\n",
      "Epoch 9/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 139ms/step - accuracy: 0.6212 - loss: 1.3974 - val_accuracy: 0.6300 - val_loss: 1.3760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3d80ecb10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_3.fit(X_train, Y_train, epochs=50, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.6252 - loss: 1.3848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.385072112083435, 0.6263999938964844]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_3.evaluate(x_test / 255.0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "best_model_3.save('cifar10_model_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Augumentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using preprocessing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,           \n",
    "    width_shift_range=0.2,       \n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,       \n",
    "    fill_mode='nearest'         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravinpb/pycode/MCW/Assignments/cifar10/cifar/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 85ms/step - accuracy: 0.5591 - loss: 1.3361 - val_accuracy: 0.7007 - val_loss: 0.8561\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 88ms/step - accuracy: 0.6152 - loss: 1.1005 - val_accuracy: 0.7050 - val_loss: 0.8756\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 89ms/step - accuracy: 0.6267 - loss: 1.0624 - val_accuracy: 0.7218 - val_loss: 0.8026\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 87ms/step - accuracy: 0.6456 - loss: 1.0195 - val_accuracy: 0.7338 - val_loss: 0.7831\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 89ms/step - accuracy: 0.6567 - loss: 0.9851 - val_accuracy: 0.7230 - val_loss: 0.8019\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 91ms/step - accuracy: 0.6669 - loss: 0.9605 - val_accuracy: 0.7244 - val_loss: 0.8330\n",
      "Epoch 7/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 89ms/step - accuracy: 0.6748 - loss: 0.9426 - val_accuracy: 0.7307 - val_loss: 0.7924\n",
      "Epoch 8/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 92ms/step - accuracy: 0.6767 - loss: 0.9225 - val_accuracy: 0.7423 - val_loss: 0.7641\n",
      "Epoch 9/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 91ms/step - accuracy: 0.6859 - loss: 0.9050 - val_accuracy: 0.7419 - val_loss: 0.7759\n",
      "Epoch 10/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 92ms/step - accuracy: 0.6908 - loss: 0.8879 - val_accuracy: 0.7518 - val_loss: 0.7237\n",
      "Epoch 11/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 90ms/step - accuracy: 0.6939 - loss: 0.8811 - val_accuracy: 0.7412 - val_loss: 0.7708\n",
      "Epoch 12/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 91ms/step - accuracy: 0.7004 - loss: 0.8584 - val_accuracy: 0.7623 - val_loss: 0.7013\n",
      "Epoch 13/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 94ms/step - accuracy: 0.7061 - loss: 0.8510 - val_accuracy: 0.7643 - val_loss: 0.6930\n",
      "Epoch 14/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 91ms/step - accuracy: 0.7063 - loss: 0.8463 - val_accuracy: 0.7427 - val_loss: 0.7569\n",
      "Epoch 15/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 90ms/step - accuracy: 0.7113 - loss: 0.8334 - val_accuracy: 0.7487 - val_loss: 0.7459\n",
      "Epoch 16/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 103ms/step - accuracy: 0.7148 - loss: 0.8256 - val_accuracy: 0.7803 - val_loss: 0.6423\n",
      "Epoch 17/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 100ms/step - accuracy: 0.7242 - loss: 0.7977 - val_accuracy: 0.7477 - val_loss: 0.7483\n",
      "Epoch 18/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 97ms/step - accuracy: 0.7210 - loss: 0.7994 - val_accuracy: 0.7672 - val_loss: 0.6790\n",
      "Epoch 19/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 90ms/step - accuracy: 0.7244 - loss: 0.7921 - val_accuracy: 0.7617 - val_loss: 0.6952\n",
      "Epoch 20/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 90ms/step - accuracy: 0.7247 - loss: 0.7863 - val_accuracy: 0.7682 - val_loss: 0.7047\n",
      "Epoch 21/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 98ms/step - accuracy: 0.7309 - loss: 0.7781 - val_accuracy: 0.7707 - val_loss: 0.6947\n",
      "Epoch 22/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 90ms/step - accuracy: 0.7265 - loss: 0.7834 - val_accuracy: 0.7809 - val_loss: 0.6613\n",
      "Epoch 23/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 91ms/step - accuracy: 0.7361 - loss: 0.7590 - val_accuracy: 0.7729 - val_loss: 0.6780\n",
      "Epoch 24/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 89ms/step - accuracy: 0.7355 - loss: 0.7601 - val_accuracy: 0.7823 - val_loss: 0.6486\n",
      "Epoch 25/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 100ms/step - accuracy: 0.7413 - loss: 0.7484 - val_accuracy: 0.7749 - val_loss: 0.6931\n",
      "Epoch 26/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 92ms/step - accuracy: 0.7419 - loss: 0.7469 - val_accuracy: 0.7388 - val_loss: 0.7903\n",
      "Epoch 27/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 92ms/step - accuracy: 0.7366 - loss: 0.7532 - val_accuracy: 0.7886 - val_loss: 0.6320\n",
      "Epoch 28/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 88ms/step - accuracy: 0.7422 - loss: 0.7344 - val_accuracy: 0.7749 - val_loss: 0.6628\n",
      "Epoch 29/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 88ms/step - accuracy: 0.7455 - loss: 0.7377 - val_accuracy: 0.7860 - val_loss: 0.6462\n",
      "Epoch 30/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 88ms/step - accuracy: 0.7481 - loss: 0.7307 - val_accuracy: 0.7907 - val_loss: 0.6400\n",
      "Epoch 31/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 89ms/step - accuracy: 0.7493 - loss: 0.7180 - val_accuracy: 0.7922 - val_loss: 0.6220\n",
      "Epoch 32/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 93ms/step - accuracy: 0.7494 - loss: 0.7268 - val_accuracy: 0.7716 - val_loss: 0.6890\n",
      "Epoch 33/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 93ms/step - accuracy: 0.7561 - loss: 0.7059 - val_accuracy: 0.7951 - val_loss: 0.6106\n",
      "Epoch 34/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 93ms/step - accuracy: 0.7591 - loss: 0.6986 - val_accuracy: 0.7862 - val_loss: 0.6297\n",
      "Epoch 35/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 90ms/step - accuracy: 0.7563 - loss: 0.7042 - val_accuracy: 0.7834 - val_loss: 0.6710\n",
      "Epoch 36/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 90ms/step - accuracy: 0.7639 - loss: 0.6884 - val_accuracy: 0.7879 - val_loss: 0.6495\n",
      "Epoch 37/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 94ms/step - accuracy: 0.7555 - loss: 0.6985 - val_accuracy: 0.7764 - val_loss: 0.6775\n",
      "Epoch 38/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 95ms/step - accuracy: 0.7569 - loss: 0.6969 - val_accuracy: 0.7991 - val_loss: 0.6049\n",
      "Epoch 39/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 97ms/step - accuracy: 0.7631 - loss: 0.6837 - val_accuracy: 0.7938 - val_loss: 0.6260\n",
      "Epoch 40/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 94ms/step - accuracy: 0.7662 - loss: 0.6772 - val_accuracy: 0.8036 - val_loss: 0.5903\n",
      "Epoch 41/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 92ms/step - accuracy: 0.7651 - loss: 0.6765 - val_accuracy: 0.7944 - val_loss: 0.6192\n",
      "Epoch 42/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 92ms/step - accuracy: 0.7647 - loss: 0.6764 - val_accuracy: 0.7974 - val_loss: 0.6139\n",
      "Epoch 43/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 94ms/step - accuracy: 0.7664 - loss: 0.6766 - val_accuracy: 0.7880 - val_loss: 0.6442\n",
      "Epoch 44/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 92ms/step - accuracy: 0.7639 - loss: 0.6822 - val_accuracy: 0.7844 - val_loss: 0.6637\n",
      "Epoch 45/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 93ms/step - accuracy: 0.7742 - loss: 0.6548 - val_accuracy: 0.7782 - val_loss: 0.6970\n",
      "Epoch 46/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 96ms/step - accuracy: 0.7700 - loss: 0.6572 - val_accuracy: 0.7821 - val_loss: 0.6593\n",
      "Epoch 47/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 97ms/step - accuracy: 0.7706 - loss: 0.6657 - val_accuracy: 0.8003 - val_loss: 0.6031\n",
      "Epoch 48/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 96ms/step - accuracy: 0.7750 - loss: 0.6522 - val_accuracy: 0.7977 - val_loss: 0.6064\n",
      "Epoch 49/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 97ms/step - accuracy: 0.7739 - loss: 0.6568 - val_accuracy: 0.7957 - val_loss: 0.6159\n",
      "Epoch 50/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 97ms/step - accuracy: 0.7721 - loss: 0.6467 - val_accuracy: 0.7998 - val_loss: 0.6278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17fca6c10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(datagen.flow(X_train, Y_train, batch_size=64),\n",
    "          epochs=50,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.7979 - loss: 0.6310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6364809274673462, 0.7967000007629395]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(x_test / 255.0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "best_model.save('cifar10_model_4.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
